large-file error handeling
Task: Implement chunked streaming + envelope encryption for large files (preserve current encryption algorithms/modes).

Context:
- Project root contains encryption code in [core/crypto_engine.py](core/crypto_engine.py) and key management in [core/key_manager.py](core/key_manager.py). Vault/file I/O lives under [vault/file_manager.py](vault/file_manager.py) (or equivalent).
- Do NOT modify the existing cipher implementations or their modes â€” call them as-is per chunk.

Requirements:
1. Envelope + streaming:
   - For each file, generate a one-time symmetric file key (AES-256 or existing symmetric cipher) and use it to encrypt/decrypt data.
   - Wrap (encrypt) that file key with the project's existing key-wrapping API in `core/key_manager.py` and store the wrapped key in per-file metadata.

2. Chunked streaming:
   - Read/write file data in fixed-size chunks (default 4 MiB; configurable).
   - For each chunk, call the existing encryption routine from `core/crypto_engine.py` to encrypt/decrypt that chunk (do not change its internals or modes).
   - Use AEAD for per-chunk integrity (reuse existing AEAD mode). Store each chunk's auth tag in metadata.

3. Nonce/IV policy:
   - Use a per-file base IV/nonce and derive/increment per-chunk nonces deterministically (e.g., base_nonce || 64-bit chunk counter or HKDF(base_nonce, chunk_index)). Ensure no nonce reuse for the same key.

4. Metadata & resume:
   - Create a small JSON metadata file alongside ciphertext containing: version, wrapped_file_key, file_iv/base_nonce, chunk_size, list of chunk entries [{offset, length, nonce, tag}], total_plain_size, and a resumable state marker.
   - Write chunks to a temporary file and only rename to final path when all chunks complete. Update metadata atomically to support resume on crash.

5. Backwards compatibility:
   - Add a `format_version` field in metadata. Small files (below threshold, e.g., 1 MiB) may still use current whole-file flow for compatibility.
   - Provide a single-line detection path: if metadata version is absent fallback to current behavior.

6. Tests & acceptance criteria:
   - Unit tests that encrypt+decrypt an example large binary (>= 200 MiB simulated by repeated pattern) and verify bitwise equality with original.
   - Test interruption/resume: simulate partial write, then resume and complete; final decrypted output must match original.
   - Memory usage must remain bounded (peak RAM << file size).
   - Add an integration test that encrypts a large PDF/DOCX file and verifies successful decrypt and integrity.

7. Deliverables:
   - Implement streaming flow in `core/crypto_engine.py` (or add `stream_encrypt_file()` / `stream_decrypt_file()` that reuses existing chunk cipher functions).
   - Update `vault/file_manager.py` to call the streaming API and handle metadata and atomic writes.
   - Add unit/integration tests under `tests/` or existing test harness.
   - Add a short doc in `docs/` explaining metadata format and resume behavior.

Implementation hints:
- Default chunk size: 4 * 1024 * 1024 bytes (configurable).
- Per-chunk nonce: 96-bit base_nonce + 32-bit counter OR derive with HKDF to the required length.
- For speed, process reading I/O and crypto in a producer/consumer queue (optional), but ensure bounded queue size to avoid memory growth.
- Keep all new code covered by tests and follow existing code style.

Acceptance: a PR that adds streaming encryption/decryption, metadata handling, tests that pass, and no changes to existing cipher/mode implementations.

If you need, implement first-pass as a new pair of functions `stream_encrypt_file(src_path, dest_path, chunk_size=4MiB)` and `stream_decrypt_file(...)` in `core/crypto_engine.py` and update `vault/file_manager.py` to call them.
